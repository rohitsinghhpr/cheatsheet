<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="../assests/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assests/css/style.css">
</head>
<body>
    <div class="details-container">
        <div class="content">
<details>
  <summary><strong>How to write manual test cases from an SRS document without the actual product/software?</strong></summary>
  <div class="content">
    Start by thoroughly reviewing the <strong>SRS (Software Requirements Specification)</strong> to understand functional and non-functional requirements. Break down each requirement into smaller, testable components, considering both positive and negative scenarios. Define clear <strong>preconditions</strong>, <strong>steps</strong>, and <strong>expected results</strong> for each test case based on the specified behavior in the SRS.
  </div>
</details>

<details>
  <summary><strong>How to write test scripts from the test cases without the actual product/software?</strong></summary>
  <div class="content">
    Use the test cases derived from the SRS as a blueprint to create the structure for test scripts. Write detailed <strong>test steps</strong>, <strong>expected outcomes</strong>, and <strong>assertions</strong>. Plan for possible functions and libraries to use in automation (e.g., setup, teardown, input validation). This is essentially <strong>pseudocode</strong> that will later be converted into executable scripts once the product is available.
  </div>
</details>

<details>
  <summary><strong>What is inclusion and exclusion?</strong></summary>
  <div class="content">
    <strong>Inclusion</strong> refers to items, conditions, or features that are explicitly covered or part of the testing scope. <strong>Exclusion</strong> defines what is not included, specifying boundaries and limitations. For example, in testing an e-commerce site, inclusion might cover the <strong>shopping cart</strong>, while exclusion could specify that <strong>payment gateway testing</strong> is out of scope.
  </div>
</details>

<details>
  <summary><strong>Entry and exit criteria (does it exist in every phase of SDLC or STLC)?</strong></summary>
  <div class="content">
    Yes, <strong>entry and exit criteria</strong> are present in both SDLC and STLC phases to ensure quality and readiness at each stage. <strong>Entry criteria</strong> are prerequisites that must be met before a phase begins, while <strong>exit criteria</strong> define what must be achieved to conclude that phase.
  </div>
</details>

<details>
  <summary><strong>Bug release vs. bug leakage</strong></summary>
  <div class="content">
    <strong>Bug Release</strong>: Releasing a software version with known low-priority bugs that do not affect critical functionality or user experience. <strong>Bug Leakage</strong>: Occurs when a bug escapes the testing phase and is found in production, indicating it was missed during testing.
  </div>
</details>

<details>
  <summary><strong>What is velocity?</strong></summary>
  <div class="content">
    In Agile, <strong>velocity</strong> is a metric representing the amount of work completed in a sprint, usually measured in story points. It helps predict the team's capacity for future sprints.
  </div>
</details>

<details>
  <summary><strong>Hotfix and patch</strong></summary>
  <div class="content">
    <strong>Hotfix</strong>: An urgent update to fix critical production bugs that need immediate resolution. <strong>Patch</strong>: A general update to fix known bugs and improve performance, often scheduled as part of regular maintenance.
  </div>
</details>

<details>
  <summary><strong>How are you assigned manual and automation testing work?</strong></summary>
  <div class="content">
    Typically, assignments are based on <strong>sprint planning</strong>, where tasks are divided according to skillset, project requirements, and team capacity. My tasks are outlined in <strong>JIRA</strong>, with manual and automation priorities specified by the QA lead.
  </div>
</details>

<details>
  <summary><strong>Whom do you submit your work to?</strong></summary>
  <div class="content">
    I submit my work to the <strong>QA lead</strong> or the <strong>Scrum Master</strong>, depending on the team structure. Additionally, all test results and defect reports are logged in our management tools, like <strong>JIRA</strong> and <strong>TestRail</strong>.
  </div>
</details>

<details>
  <summary><strong>How many test cases do you automate per day?</strong></summary>
  <div class="content">
    On average, I can automate around <strong>3-5 test cases</strong> per day, depending on complexity. Simpler cases take less time, while complex ones may require additional scripting and debugging.
  </div>
</details>

<details>
  <summary><strong>How to make Selenium test cases run faster?</strong></summary>
  <div class="content">
    Optimize test scripts by using <strong>implicit/explicit waits</strong> effectively, avoiding hard waits, running tests in parallel, using <strong>headless mode</strong> for browser tests, and minimizing interactions with the browser whenever possible.
  </div>
</details>

<details>
  <summary><strong>How do you raise a bug?</strong></summary>
  <div class="content">
    I raise a bug in <strong>JIRA</strong>, providing a detailed description, steps to reproduce, environment details, severity, screenshots, and expected vs. actual behavior to help developers understand and resolve the issue.
  </div>
</details>

<details>
  <summary><strong>How to create test scenarios? (with examples)</strong></summary>
  <div class="content">
    Identify core functionalities and potential user flows. For a login feature, scenarios could include:
    <ul>
      <li><strong>Valid login credentials</strong></li>
      <li><strong>Invalid login credentials</strong></li>
      <li><strong>Password reset functionality</strong></li>
      <li><strong>Login from multiple devices</strong></li>
    </ul>
  </div>
</details>

<details>
  <summary><strong>How did you handle a mistake that was made?</strong></summary>
  <div class="content">
    When I make a mistake, I first assess the impact, then address and correct it quickly. I inform the team, learn from it, and update any relevant documentation or processes to prevent future occurrences.
  </div>
</details>

<details>
  <summary><strong>What would you do if a team member is unable to complete a task for a sprint?</strong></summary>
  <div class="content">
    I would assess if I or someone else on the team could assist to ensure task completion. Additionally, I’d communicate with the <strong>Scrum Master</strong> about possible adjustments to the sprint’s scope.
  </div>
</details>

<details>
  <summary><strong>How would you handle conflict within the team?</strong></summary>
  <div class="content">
    I’d approach it constructively, listening to both sides, focusing on facts, and working towards a solution that benefits the project and maintains team harmony.
  </div>
</details>

<details>
  <summary><strong>How would you deal with a difficult stakeholder?</strong></summary>
  <div class="content">
    I’d maintain clear, respectful communication, provide regular updates, listen to their concerns, and manage expectations effectively. Ensuring transparency often helps build trust.
  </div>
</details>

<details>
  <summary><strong>What are the QA challenges related to Agile software development?</strong></summary>
  <div class="content">
    Challenges include limited time for testing, adapting to continuous changes, maintaining test automation stability, and ensuring thorough coverage within short sprint cycles.
  </div>
</details>

<details>
  <summary><strong>Difference between testing and debugging</strong></summary>
  <div class="content">
    <strong>Testing</strong> involves finding defects by executing the software, while <strong>debugging</strong> is the developer's process of identifying, analyzing, and fixing those defects.
  </div>
</details>

<details>
  <summary><strong>What is Test Observability in Software Testing?</strong></summary>
  <div class="content">
    <strong>Test observability</strong> means the ability to monitor and understand the software’s internal state and behavior during testing, enhancing the ability to detect issues.
  </div>
</details>

<details>
  <summary><strong>What is a Test Log?</strong></summary>
  <div class="content">
    A <strong>Test Log</strong> is a detailed record of all executed test activities, showing the date, time, executed tests, pass/fail results, and any anomalies found.
  </div>
</details>

<details>
  <summary><strong>Hotfix vs Patch: Core Differences</strong></summary>
  <div class="content">
    <strong>Hotfixes</strong> are immediate fixes for critical production issues, while <strong>patches</strong> are scheduled updates for multiple fixes and improvements.
  </div>
</details>

<details>
  <summary><strong>Code Coverage vs Test Coverage</strong></summary>
  <div class="content">
    <strong>Code coverage</strong> measures how much code is executed during testing, while <strong>test coverage</strong> assesses how much of the functional requirements are tested.
  </div>
</details>

<details>
  <summary><strong>Verification and Validation in Software Testing with examples</

strong></summary>
  <div class="content">
    <strong>Verification</strong>: Ensuring the product is built correctly according to specifications (e.g., code reviews, inspections). <strong>Validation</strong>: Ensuring the product meets user needs and functions as intended (e.g., UAT, functional testing).
  </div>
</details>

<details>
  <summary><strong>What is a patch?</strong></summary>
  <div class="content">
    A <strong>patch</strong> is an update that fixes known bugs or improves system performance, typically part of routine maintenance.
  </div>
</details>

<details>
  <summary><strong>Types of bugs, explain</strong></summary>
  <div class="content">
    <ul>
      <li><strong>Functional Bugs</strong>: Related to the functionality not working as expected.</li>
      <li><strong>Performance Bugs</strong>: Issues affecting speed or responsiveness.</li>
      <li><strong>Security Bugs</strong>: Vulnerabilities allowing unauthorized access.</li>
      <li><strong>UI Bugs</strong>: Problems with layout, formatting, or visual elements.</li>
      <li><strong>Compatibility Bugs</strong>: Issues when software doesn’t work across different devices or browsers.</li>
    </ul>
  </div>
</details>
        </div>
        <hr/>
        <div class="content">
            <details>
                <summary>What is Defect Age?</summary>
                <div class="content">
                  <p><strong>Defect Age</strong> refers to the time elapsed from when a defect is reported or discovered until it is resolved or closed. This metric helps evaluate the efficiency of the defect management process and can indicate:</p>
                  <ul>
                    <li><strong>Time to Resolution</strong>: How long it takes to fix defects after they are reported.</li>
                    <li><strong>Process Efficiency</strong>: The effectiveness of the development and testing teams in addressing issues promptly.</li>
                  </ul>
                  <p><strong>Defect Age</strong> can help identify bottlenecks in the defect resolution process, allowing teams to improve overall project management and quality assurance practices.</p>
                </div>
              </details>
              
              <details>
                <summary>What is a Library?</summary>
                <div class="content">
                  <p>A <strong>Library</strong> is a collection of pre-written code that developers can use to perform common tasks or solve specific problems. It provides reusable functions, classes, or modules that can be integrated into your own applications. Key points about libraries:</p>
                  <ul>
                    <li>Libraries contain modular, reusable code.</li>
                    <li>Developers can avoid reinventing the wheel by leveraging libraries for common functionalities like data manipulation, networking, or user interface components.</li>
                    <li>Unlike frameworks, libraries do not dictate the structure of an application, allowing more flexibility for developers.</li>
                  </ul>
                </div>
              </details>
              
              <details>
                <summary>What is a Framework?</summary>
                <div class="content">
                  <p>A <strong>Framework</strong> is a more comprehensive tool that provides a foundation for developing applications. It dictates the structure and design of the application and often includes libraries as part of its offering. Key points about frameworks:</p>
                  <ul>
                    <li><strong>Inversion of Control</strong>: Frameworks often implement the principle of inversion of control, meaning the framework controls the flow of the application and calls your code at specific points (via hooks or callbacks). This is sometimes referred to as the "Hollywood Principle" — "Don't call us, we'll call you."</li>
                    <li><strong>Built-in Features</strong>: Frameworks provide a broad set of built-in features and tools, which can include libraries, but also conventions, patterns, and best practices for structuring applications.</li>
                    <li><strong>Opinionated</strong>: Frameworks tend to be more opinionated about how an application should be designed and structured. They often enforce certain practices and patterns.</li>
                  </ul>
                </div>
              </details>
              
              <details>
                <summary>What is Error Seeding?</summary>
                <div class="content">
                  <p><strong>Error Seeding</strong> is the process of intentionally adding known errors into a program to evaluate the effectiveness of error detection methods and tools. It helps in assessing the skills of testers in finding bugs and understanding the reliability of the application. Some key points about error seeding:</p>
                  <ul>
                    <li>It helps determine the error detection rate by comparing the number of seeded errors found against the total number of errors introduced.</li>
                    <li>It provides insights into the skill levels of testers and the robustness of the error detection process.</li>
                    <li>It is useful in estimating the effectiveness of the testing process and can highlight areas where improvements are needed.</li>
                  </ul>
                </div>
              </details>
              
        </div>
        <hr/>
        <div class="content">
            <details>
                <summary>Describe the end-to-end workflow of an automation project you have worked on.</summary>
                <div class="content">
                  In one of my automation projects, the workflow began with a comprehensive analysis of the requirements, where I collaborated with the business team to understand key functionalities and user expectations. Next, I identified the test scenarios to automate and prioritized them based on factors like criticality and frequency of use. Once the framework was established, I created and executed scripts while continuously refining them based on test feedback. Finally, I integrated the tests into the CI/CD pipeline, monitored execution, and generated detailed reports for stakeholders.
                </div>
              </details>
              
              <details>
                <summary>What was the project's goal?</summary>
                <div class="content">
                  The project aimed to automate regression testing for a web application, allowing faster and more consistent testing. This approach reduced manual testing time, enabling the team to focus on exploratory testing and accelerating the release cycle without compromising quality.
                </div>
              </details>
              
              <details>
                <summary>Which tools and technologies did you use?</summary>
                <div class="content">
                  For this project, I used Selenium WebDriver for browser automation, TestNG as the test runner, and Maven for dependency management. Git was used for version control, and I set up Jenkins for Continuous Integration (CI) to trigger automated tests after each code change. Additionally, I used Allure for report generation to provide clear and detailed feedback on test results.
                </div>
              </details>
              
              <details>
                <summary>How did you handle errors and exceptions?</summary>
                <div class="content">
                  I used try-catch blocks to manage exceptions and implemented custom error-handling methods that captured detailed logs whenever a test encountered an error. Screenshots were also automatically taken for any failures, providing insights for quick debugging. Additionally, I set up notifications for any critical errors, so they could be addressed immediately.
                </div>
              </details>
              
              <details>
                <summary>How do you prioritize tasks and manage time when working on multiple automation projects?</summary>
                <div class="content">
                  I prioritize tasks based on project deadlines, complexity, and the potential impact on overall quality. I usually start by completing high-impact scripts, then address less critical cases. Effective time management involves breaking down each project into smaller tasks, setting realistic deadlines, and using tools like JIRA to track progress. Regular stand-up meetings and reviews also help keep track of multiple projects simultaneously.
                </div>
              </details>
              
              <details>
                <summary>Can you explain the concept of Continuous Integration/Continuous Deployment (CI/CD) and its importance in automation?</summary>
                <div class="content">
                  CI/CD involves automatically integrating code changes, testing, and deploying applications continuously throughout the development cycle. This is essential in automation because it allows automated tests to be triggered whenever code changes occur, providing rapid feedback and enabling teams to detect issues early. Continuous testing through CI/CD pipelines ensures quality and reduces the time needed to release features to production.
                </div>
              </details>
              
              <details>
                <summary>How do you integrate automated tests into the CI/CD pipeline?</summary>
                <div class="content">
                  I set up the CI/CD pipeline in Jenkins, where tests are triggered with every code commit or pull request. Using tools like GitHub Actions or Jenkins plugins, I automate the execution of test suites, and the results are logged for each build. This setup provides quick feedback to developers, allowing them to address issues before they reach production.
                </div>
              </details>
              
              <details>
                <summary>Describe any specific tools or plugins you use.</summary>
                <div class="content">
                  In addition to Selenium and Jenkins, I frequently use Allure Reports for creating detailed, interactive test reports. I also use Extent Reports for additional logging and reporting customization. For code quality checks, I implement SonarQube in the CI/CD pipeline to maintain high code standards, and I use Maven for dependency management.
                </div>
              </details>
              
              <details>
                <summary>How do you handle test results and reporting?</summary>
                <div class="content">
                  I generate test reports using Allure or Extent Reports, which provide comprehensive insights into test execution, including pass/fail statuses, execution times, and screenshots for failures. These reports are shared with stakeholders and serve as documentation for each test run. Additionally, I set up automated email notifications for critical failures, so the team can address issues promptly.
                </div>
              </details>
              
              <details>
                <summary>How do you design an automation framework from scratch?</summary>
                <div class="content">
                  To design an automation framework from scratch, I begin by understanding the project requirements and deciding on the framework type, such as data-driven or page-object model. I then define folder structures for modularity, set up base classes for browser and reporting configurations, and implement reusable components like custom logging, reporting, and error handling. Finally, I ensure the framework can easily integrate with CI/CD tools and supports parallel test execution.
                </div>
              </details>
              
              <details>
                <summary>What are the key components you consider?</summary>
                <div class="content">
                  Key components include a robust reporting mechanism, reusable utilities and helper functions, modular page object models, efficient error handling routines, and compatibility with CI/CD. Scalability, maintainability, and ease of use are also critical, ensuring the framework can adapt as project requirements evolve.
                </div>
              </details>
              
              <details>
                <summary>How do you ensure scalability and maintainability?</summary>
                <div class="content">
                  Scalability is achieved by structuring the framework to allow easy addition of new tests and support for parallel execution. For maintainability, I apply design patterns like the Page Object Model (POM) and follow coding best practices to reduce dependencies. Regular code reviews and updates ensure that the framework remains clean, efficient, and easy to understand for new team members.
                </div>
              </details>
              
              <details>
                <summary>Explain how you would automate a complex business process that involves multiple systems and data sources.</summary>
                <div class="content">
                  For a complex business process, I first map out each system's interactions and dependencies. I then develop test scripts for each component and use a modular approach to handle individual processes. I also use API testing to simulate data inputs and outputs between systems, reducing the need for UI-based testing where possible. Additionally, I use service virtualization for any third-party systems, ensuring stable and repeatable test environments.
                </div>
              </details>
              
              <details>
                <summary>What are some best practices you follow for writing and maintaining automated test scripts?</summary>
                <div class="content">
                  I follow best practices such as writing clear, modular scripts, adhering to naming conventions, and using reusable functions wherever possible. I keep test data separate from scripts (data-driven testing) to enhance reusability, and I maintain clear documentation. Regularly reviewing and updating scripts ensures they remain aligned with application updates, reducing maintenance costs over time.
                </div>
              </details>
              
              <details>
                <summary>Describe your experience with version control systems like Git in the context of automation.</summary>
                <div class="content">
                  In automation, I use Git to manage code versions, collaborate with team members, and maintain a history of changes. Branching strategies like feature branches and pull requests allow for clean integration and testing before merging into the main branch. I also use Git to manage code reviews and resolve conflicts, ensuring a stable, consistent codebase.
                </div>
              </details>
              
              <details>
                <summary>Describe a time when an automated process you implemented failed. How did you identify the issue and what steps did you take to resolve it?</summary>
                <div class="content">
                  During a test run, an automation script failed due to a recent UI update that changed element locators. I identified the issue by reviewing the logs and debugging the failing test. I updated the locators in the Page Object Model and added more flexible locators to handle similar UI changes in the future, reducing the chances of similar failures.
                </div>
              </details>
              
              <details>
                <summary>How do you handle flaky tests in your automation suite?</summary>
                <div class="content">
                  For flaky tests, I investigate the root cause to determine if it's due to timing issues, dynamic elements, or dependencies on external data. I apply explicit waits and retry mechanisms to handle timing issues and use stable locators. I also isolate flaky tests to monitor and refine them until they run consistently.
                </div>
              </details>
              
              <details>
                <summary>What strategies do you use to ensure your automation scripts are resilient and reliable?</summary>
                <div class="content">
                  I use strategies like error handling, retry logic, and custom waits to handle timing issues, making the scripts more resilient to UI changes and network delays. Modularizing the scripts allows for easy updates, and regular code reviews ensure scripts remain clean and reliable.
                </div>
              </details>
              
              <details>
                <summary>Explain the role of service virtualization in automation. How have you used it in your projects?</summary>
                <div class="content">
                  Service virtualization allows simulation of dependent systems or components that may not be available in the test environment. I’ve used it to create mock responses for APIs, ensuring consistent and repeatable tests even when some services were down or under development. This approach allows for comprehensive testing without relying on external systems.
                </div>
              </details>
              
              <details>
                <summary>How do you collaborate with developers, QA, and other stakeholders during the automation process?</summary>
                <div class="content">
                  Collaboration involves regular communication with developers to align on test coverage and clarify any changes to the codebase. I attend sprint planning and daily stand-ups to discuss progress and blockers. I work closely with QA team members to prioritize test cases and align on test scenarios, and I keep stakeholders updated with reports on test results, progress, and any issues encountered in the automation process.
                </div>
              </details>
              
        </div>
    </div>
    <div class="home-link">
        <a class="btn btn-primary" href="../index.html">Home</a>
    </div>
    <script src="../assests/js/bootstrap.bundle.min.js"></script>
</body>
</html>